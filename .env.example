# ─── Required ────────────────────────────────────────────────────────────────
WEBHOOK_SECRET=change-me
SESSION_SECRET=change-me

# ─── Auth — root admin bootstrapped on first run ──────────────────────────────
ADMIN_EMAIL=admin@example.com
ADMIN_PASSWORD=changeme
JWT_SECRET=change-me-in-production

# ─── API Key (optional) — for CI/CD service-to-service calls ─────────────────
# Set this to a strong random string, then use it as:
#   Authorization: Bearer <API_KEY>
# This bypasses cookie auth so pipelines don't need a login step.
# API_KEY=generate-a-strong-secret-here

# ─── LLM ─────────────────────────────────────────────────────────────────────
# AgnusAI talks to LLMs via API — run your model server separately.
# Ollama: https://ollama.com/download  (ollama serve)
# OpenAI, Azure OpenAI, or any OpenAI-compatible endpoint also work.

# Option A: local Ollama (run `ollama serve` on your host)
LLM_PROVIDER=ollama
LLM_BASE_URL=http://localhost:11434/v1
LLM_MODEL=qwen3.5:397b-cloud

# Option B: OpenAI
# LLM_PROVIDER=openai
# LLM_API_KEY=sk-...
# LLM_MODEL=gpt-4o-mini

# Option C: Azure OpenAI
# LLM_PROVIDER=azure
# LLM_BASE_URL=https://your-resource.openai.azure.com/openai/deployments/gpt-4o
# LLM_API_KEY=...

# ─── Embeddings ───────────────────────────────────────────────────────────────
# Leave EMBEDDING_PROVIDER unset to disable embeddings (standard/fast review depth).
# Set it to enable deep mode (2-hop + semantic neighbor search via pgvector).

# Option A: local Ollama (run `ollama pull qwen3-embedding:0.6b` first)
# EMBEDDING_PROVIDER=ollama
# EMBEDDING_BASE_URL=http://localhost:11434
# EMBEDDING_MODEL=qwen3-embedding:0.6b    # 639MB, 40K ctx, #1 MTEB multilingual

# Option B: OpenAI
# EMBEDDING_PROVIDER=openai
# EMBEDDING_MODEL=text-embedding-3-small  # 1536-dim, $0.02/1M tokens
# EMBEDDING_API_KEY=sk-...

# Option C: Google (free tier: 1500 RPM)
# EMBEDDING_PROVIDER=google
# EMBEDDING_MODEL=text-embedding-004      # 768-dim
# EMBEDDING_API_KEY=AIza...

# Option D: Any OpenAI-compatible endpoint (Cohere, Together, Voyage, Azure, etc.)
# EMBEDDING_PROVIDER=http
# EMBEDDING_BASE_URL=https://api.cohere.com/compatibility/v1
# EMBEDDING_MODEL=embed-v4.0
# EMBEDDING_API_KEY=...

# ─── Review depth ─────────────────────────────────────────────────────────────
# fast     — 1-hop graph traversal, no embeddings
# standard — 2-hop graph traversal, no embeddings (default, no Ollama needed)
# deep     — 2-hop + semantic neighbors via embedding search (requires EMBEDDING_PROVIDER)
REVIEW_DEPTH=standard

# ─── VCS tokens ───────────────────────────────────────────────────────────────
GITHUB_TOKEN=ghp_...
AZURE_DEVOPS_TOKEN=
