# â”€â”€â”€ Required â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
WEBHOOK_SECRET=change-me
SESSION_SECRET=change-me

# â”€â”€â”€ Auth â€” root admin bootstrapped on first run â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ADMIN_EMAIL=admin@example.com
ADMIN_PASSWORD=changeme
JWT_SECRET=change-me-in-production

# â”€â”€â”€ API Key (optional) â€” for CI/CD service-to-service calls â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Set this to a strong random string, then use it as:
#   Authorization: Bearer <API_KEY>
# This bypasses cookie auth so pipelines don't need a login step.
# API_KEY=generate-a-strong-secret-here

# â”€â”€â”€ LLM â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Set LLM_PROVIDER to select your provider, then fill in the matching section.
# Supported: ollama | openai | azure | claude | custom

LLM_PROVIDER=ollama
LLM_MODEL=qwen3.5:397b-cloud

# Option A: local Ollama (run `ollama serve` on your host)
OLLAMA_BASE_URL=http://localhost:11434/v1

# Option B: OpenAI
# LLM_PROVIDER=openai
# LLM_MODEL=gpt-4o-mini
# OPENAI_API_KEY=sk-proj-...

# Option C: Azure OpenAI (supports both openai.azure.com and cognitiveservices.azure.com)
# LLM_PROVIDER=azure
# LLM_MODEL=gpt-4o-mini                         # deployment name
# AZURE_OPENAI_ENDPOINT=https://your-resource.cognitiveservices.azure.com/openai/deployments/gpt-4o-mini
# AZURE_OPENAI_API_KEY=...
# AZURE_API_VERSION=2025-01-01-preview           # optional, this is the default

# Option D: Anthropic / Claude
# LLM_PROVIDER=claude
# LLM_MODEL=claude-sonnet-4-6
# ANTHROPIC_API_KEY=sk-ant-...

# Option E: Any OpenAI-compatible endpoint (vLLM, LM Studio, Together, Groq, etc.)
# LLM_PROVIDER=custom
# LLM_MODEL=meta-llama/Llama-3-70b-instruct
# CUSTOM_LLM_URL=https://api.together.xyz/v1
# CUSTOM_LLM_API_KEY=...

# â”€â”€â”€ Embeddings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Leave EMBEDDING_PROVIDER unset to disable embeddings (standard/fast review depth).
# Set it to enable deep mode (2-hop + semantic neighbor search via pgvector).

# Option A: local Ollama (run `ollama pull qwen3-embedding:0.6b` first)
# EMBEDDING_PROVIDER=ollama
# EMBEDDING_BASE_URL=http://localhost:11434
# EMBEDDING_MODEL=qwen3-embedding:0.6b    # 639MB, 40K ctx, #1 MTEB multilingual

# Option B: OpenAI
# EMBEDDING_PROVIDER=openai
# EMBEDDING_MODEL=text-embedding-3-small  # 1536-dim, $0.02/1M tokens
# EMBEDDING_API_KEY=sk-...

# Option C: Google (free tier: 1500 RPM)
# EMBEDDING_PROVIDER=google
# EMBEDDING_MODEL=text-embedding-004      # 768-dim
# EMBEDDING_API_KEY=AIza...

# Option D: Azure OpenAI embeddings (uses same AZURE_API_VERSION as LLM)
# EMBEDDING_PROVIDER=azure
# EMBEDDING_BASE_URL=https://your-resource.cognitiveservices.azure.com/openai/deployments/text-embedding-ada-002
# EMBEDDING_MODEL=text-embedding-ada-002
# EMBEDDING_API_KEY=...

# Option E: Any OpenAI-compatible endpoint (Cohere, Together, Voyage, etc.)
# EMBEDDING_PROVIDER=http
# EMBEDDING_BASE_URL=https://api.cohere.com/compatibility/v1
# EMBEDDING_MODEL=embed-v4.0
# EMBEDDING_API_KEY=...

# â”€â”€â”€ Review depth â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# fast     â€” 1-hop graph traversal, no embeddings
# standard â€” 2-hop graph traversal, no embeddings (default, no Ollama needed)
# deep     â€” 2-hop + semantic neighbors via embedding search (requires EMBEDDING_PROVIDER)
REVIEW_DEPTH=standard

# â”€â”€â”€ Feedback links in review comments â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Public URL of this server â€” used to build ğŸ‘/ğŸ‘ links in PR comments.
# If unset, feedback links are silently omitted.
BASE_URL=http://localhost:3000
# HMAC secret for signing feedback URLs. Defaults to WEBHOOK_SECRET if unset.
FEEDBACK_SECRET=change-me

# â”€â”€â”€ VCS tokens â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
GITHUB_TOKEN=ghp_...
AZURE_DEVOPS_TOKEN=
