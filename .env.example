# LLM Provider Configuration
# Provider: ollama, openai, azure, or custom
LLM_PROVIDER=ollama
LLM_MODEL=qwen3.5:cloud

# Ollama (local, no API key needed)
OLLAMA_BASE_URL=http://localhost:11434/v1

# OpenAI
OPENAI_API_KEY=sk-...
OPENAI_BASE_URL=https://api.openai.com/v1

# Azure OpenAI
AZURE_OPENAI_KEY=
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/openai/deployments/your-deployment

# Custom OpenAI-compatible endpoint
CUSTOM_API_KEY=
CUSTOM_ENDPOINT=

# GitHub (required for PR access)
GITHUB_TOKEN=ghp_...

# Azure DevOps (if using Azure VCS)
AZURE_DEVOPS_TOKEN=