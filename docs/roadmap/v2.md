# v2 Roadmap â€” Graph-Aware Code Reviewer

## What v2 Is

v2 evolves the current CLI reviewer from diff-aware to **system-aware**. Instead of only seeing changed lines, the reviewer understands the entire codebase â€” dependency graph, call chains, blast radius, interface contracts.

The current AgnusAI CLI is **Layer 0** and does not change. Everything new wraps around it. The only modification to the existing reviewer is adding a `context` parameter to the prompt that gets populated by the new graph layer.

---

## Build Layers â€” Follow This Order

> **Rule: never build a layer before the one below it is stable and tested.**

| Layer | What | Status |
|-------|------|--------|
| **Layer 0** | LLM caller + CLI (AgnusAI current) | âœ… Exists â€” do not break |
| **Layer 1** | Indexing pipeline (parser, graph, storage, retriever) | âŒ Not started |
| **Layer 2** | API server (Fastify, webhooks, SSE) | âŒ Not started |
| **Layer 3** | CI adapters (GitHub Actions + Azure Pipelines) | âŒ Not started |
| **Layer 4** | Dashboard + Auth (Next.js, GitHub OAuth + Azure AD) | âŒ Not started |
| **Layer 5** | Self-host packaging (Docker Compose) | âŒ Not started |

---

## Monorepo Structure (Target)

```
/
â”œâ”€â”€ packages/
â”‚   â”œâ”€â”€ core/                     # Engine â€” indexing, graph, retrieval
â”‚   â”‚   â””â”€â”€ src/
â”‚   â”‚       â”œâ”€â”€ parser/           # Tree-sitter wrappers per language
â”‚   â”‚       â”œâ”€â”€ graph/            # Symbol graph: build, store, traverse
â”‚   â”‚       â”œâ”€â”€ embeddings/       # Embed symbols, vector search
â”‚   â”‚       â”œâ”€â”€ indexer/          # Orchestrate full + incremental indexing
â”‚   â”‚       â”œâ”€â”€ retriever/        # Given a diff, fetch relevant context
â”‚   â”‚       â”œâ”€â”€ reviewer/         # â† EXISTING LLM caller lives here (Layer 0)
â”‚   â”‚       â””â”€â”€ storage/          # DB adapters (SQLite / Postgres, swappable)
â”‚   â”‚
â”‚   â”œâ”€â”€ api/                      # Fastify API server
â”‚   â”‚   â””â”€â”€ src/
â”‚   â”‚       â”œâ”€â”€ routes/
â”‚   â”‚       â”œâ”€â”€ webhooks/         # GitHub + Azure webhook handlers
â”‚   â”‚       â”œâ”€â”€ auth/             # OAuth handlers
â”‚   â”‚       â””â”€â”€ sse/              # Live indexing progress
â”‚   â”‚
â”‚   â”œâ”€â”€ dashboard/                # Next.js frontend
â”‚   â””â”€â”€ shared/                   # Types + Zod schemas shared across packages
â”‚
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ .env.example
```

The current `src/` becomes `packages/core/src/reviewer/` â€” no logic changes, just moved into the monorepo.

---

## Layer 1 â€” Indexing Pipeline

This is the core of v2. Everything below makes the existing reviewer dramatically better by giving it codebase context before it reviews a diff.

### Key Types (`packages/shared/src/types.ts`)

```typescript
type SymbolKind = 'function' | 'class' | 'method' | 'interface' | 'const' | 'type'

type EdgeKind = 'calls' | 'imports' | 'inherits' | 'implements' | 'uses' | 'overrides'

interface ParsedSymbol {
  id: string              // "src/auth/service.ts:AuthService.login"
  filePath: string
  name: string
  qualifiedName: string   // "AuthService.login"
  kind: SymbolKind
  signature: string       // "login(credentials: Credentials): Promise<User>"
  bodyRange: [number, number]
  docComment?: string
  repoId: string
}

interface BlastRadius {
  directCallers: ParsedSymbol[]      // 1 hop up the call graph
  transitiveCallers: ParsedSymbol[]  // 2 hops up
  affectedFiles: string[]
  riskScore: number                  // 0â€“100
}

// What gets injected into the LLM prompt
interface GraphReviewContext {
  diff: string
  changedSymbols: ParsedSymbol[]
  callers: ParsedSymbol[]
  callees: ParsedSymbol[]
  blastRadius: BlastRadius
  semanticNeighbors: ParsedSymbol[]
}
```

### Parser â€” Tree-sitter (not LSP)

Tree-sitter is the right tool for symbol extraction â€” **not LSP servers**. It's an incremental parsing library that builds a concrete syntax tree (CST), re-parses only changed nodes, and is deterministic (no hallucinated relationships).

| Language | Parser |
|----------|--------|
| TypeScript / JavaScript | `tree-sitter-typescript` |
| Python | `tree-sitter-python` |
| Go | `tree-sitter-go` |
| Java | `tree-sitter-java` |
| Rust | `tree-sitter-rust` |

**Build TypeScript first, Python second, Go third.**

Key node types for TypeScript:
- `function_declaration`, `arrow_function`, `method_definition`
- `class_declaration`, `interface_declaration`
- `import_statement`, `export_statement`

### Symbol Graph â€” In-Memory (not Neo4j)

`InMemorySymbolGraph` is an adjacency list with BFS traversal. For a single repo up to ~100k symbols this is microseconds. Persist symbols + edges to SQL; load into memory on startup; patch incrementally.

**Do not use Neo4j.** In-memory + SQL is sufficient at this scale and eliminates ops complexity.

```
graph.getCallers(symbolId, hops=2)   â†’ who calls this? (walk inEdges)
graph.getCallees(symbolId, hops=1)   â†’ what does this call? (walk outEdges)
graph.getBlastRadius(symbolIds)      â†’ full impact: files + risk score
graph.removeFile(filePath)           â†’ called before re-parsing a changed file
```

**1-2 hop traversal is the sweet spot.** Beyond 2 hops, token costs balloon with diminishing returns.

### Storage â€” SQLite default, Postgres for cloud

| Mode | When |
|------|------|
| SQLite + sqlite-vec | Default for self-hosting (zero infra, just a file at `.review-cache/index.db`) |
| Postgres + pgvector | Cloud deployment, teams with large repos |

Switch via `STORAGE_MODE=sqlite|postgres`. Both implement the same `StorageAdapter` interface.

**Do not store raw source code.** Store symbols, edges, and embeddings only. This is a hard privacy constraint.

### Indexer â€” Full + Incremental

```
Full index (run once when repo is connected):
  Parse all files â†’ extract symbols â†’ build graph â†’ embed â†’ save to DB

Incremental (run on every PR):
  For each changed file:
    removeFile(path) â†’ re-parse â†’ upsert symbols/edges â†’ re-embed
  Only touch changed files â€” never re-index the whole repo
```

For 10 changed files, only 10 files worth of work regardless of repo size.

### Retriever â€” Graph-Augmented RAG

The retriever is what makes the reviewer system-aware:

```
diff â†’ extract changed symbols
     â†’ look up in dependency graph
     â†’ BFS 1-2 hops: callers + callees
     â†’ semantic neighbors (vector search, deduplicated against graph results)
     â†’ serialize for prompt (signatures for distant nodes, full source for direct)
```

**70% token reduction** vs. naive "dump related files" â€” achieved by sending signatures + docstrings for distant neighbors and full bodies only for direct neighbors.

### Connecting to the Existing Reviewer (Layer 0)

**This is the only change to the existing LLM caller:**

```typescript
// Before
return this.llm.review({ diff })

// After â€” context param added
const context = await this.retriever.getReviewContext(diff, repoId)
return this.llm.review({ diff, context: this.retriever.serializeForPrompt(context) })
```

In the existing prompt template, add before the diff:

```
## Codebase Context
{context}

## Code Diff to Review
{diff}
```

---

## Layer 2 â€” API Server (Fastify)

### Key Endpoints

```
POST   /api/repos                        Register a repo
POST   /api/repos/:id/index              Trigger full index
GET    /api/repos/:id/index/status       SSE stream of indexing progress
GET    /api/repos/:id/graph/blast-radius/:symbolId

POST   /api/repos/:id/review             Run review on a diff
POST   /api/webhooks/github              GitHub PR webhook
POST   /api/webhooks/azure               Azure DevOps webhook

GET    /api/auth/github                  OAuth flow (GitHub + Azure AD)
```

SSE (not WebSockets) for indexing progress â€” simpler, works through proxies, one-directional.

---

## Layer 3 â€” CI Adapters

Both GitHub Actions and Azure Pipelines behind one `CIAdapter` interface. The dashboard pre-fills the YAML with the repo's actual ID â€” users copy and paste, never manually configure.

---

## Layer 4 â€” Dashboard (Next.js)

### Pages (build in this order)

```
/login                      GitHub + Azure login
/onboarding/connect         Repo picker with CI detection
/onboarding/indexing        Live SSE progress (step list + bar)
/onboarding/ready           Payoff screen: stats + top hubs + CI YAML
/dashboard                  Review history
/settings                   Review depth (Fast / Standard / Deep)
```

**Do not surface `graph_depth` to users.** Use human labels: Fast (1 hop) / Standard (2 hops) / Deep (2 hops + semantic).

---

## Layer 5 â€” Self-Host Packaging

`docker compose up` with 5 env vars maximum. SQLite mode works with no Postgres. Postgres optional via `STORAGE_MODE=postgres`.

Required vars: `SECRET_KEY`, `GITHUB_CLIENT_ID`, `GITHUB_CLIENT_SECRET`, `LLM_PROVIDER`, `LLM_API_KEY`.

---

## Research-Backed Feature Priorities

These features address the root causes of why AI code review fails (based on benchmark research showing 39â€“49% F1 and 40% alert ignore rates). They map into the layers above.

| Priority | Feature | Layer | Impact | Status |
|----------|---------|-------|--------|--------|
| **P1** | Graph-aware context (Tree-sitter + BFS retriever) | Layer 1 | ğŸ”´ High | Not Started |
| **P1** | Precision-first output (confidence threshold) | Layer 0 mod | ğŸ”´ High | Not Started |
| **P1** | Institutional memory (team decision store) | Layer 1/2 | ğŸ”´ High | Not Started |
| **P2** | Intent / ticket verification (Jira/GitHub Issues) | Layer 2 | ğŸ”´ High | Not Started |
| **P2** | Production metadata injection (git signals) | Layer 1 | ğŸ”´ High | Not Started |
| **P2** | TypeScript type diagnostics (`tsc` + Tree-sitter) | Layer 1 | ğŸŸ¡ Medium | Not Started |
| **P2** | Codebase embeddings (vector search layer) | Layer 1 | ğŸ”´ High | Not Started |
| **P3** | Cross-repository impact analysis | v2+ | ğŸ”´ High | Not Started |

### P1: Precision-First Output

Confidence threshold per comment â€” if nothing clears the bar, post nothing. "This PR looks good" is a valid output. Targets the alert fatigue problem.

- Add `confidence: number` to `ReviewComment`
- LLM self-scores each comment in output
- Configurable threshold (default `0.7`) applied in `filterComments()`

### P1: Institutional Memory

Store team decisions from review threads as YAML rules; enforce them on future PRs touching the same files.

- Persist in `~/.pr-review/memory/` (no DB required)
- Index by file glob pattern
- Inject matching rules into review prompt as team constraints
- CLI: `agnus remember "payments service uses pessimistic locking"`

### P2: Intent / Ticket Verification

Fetch linked Jira/GitHub issue, extract acceptance criteria, verify the diff satisfies each one.

- Jira + Linear adapters already stubbed in `src/adapters/ticket/`
- Inject ticket context + acceptance criteria into prompt
- Review includes an "Intent Check" section: âœ… / âŒ / âš ï¸ per criterion

### P2: Production Metadata Injection

Inject git-derived signals into context so the LLM calibrates review depth.

```typescript
// Cheapest signals â€” zero external dependencies
{ path, commitCount30d, daysSinceLastChange, authorCount }
// â†’ "âš ï¸ src/payments/charge.ts â€” 23 changes in 30 days, 8 authors"
```

Later: APM error rates, incident tags from PagerDuty/Opsgenie.

### P3: Cross-Repository Impact Analysis

When a shared interface/DTO changes, automatically surface all downstream consumers across repos. Requires a service mesh graph connecting repos via their published API contracts (OpenAPI, gRPC protos, GraphQL schemas). This is v2+ after single-repo graph is stable.

---

## Definition of Done for v1

A user can:
1. Sign up with GitHub or Azure AD
2. Connect a repo and watch it index with live progress
3. See top dependency hubs on the payoff screen
4. Copy pre-filled CI YAML from the dashboard
5. Open a PR and receive a review that references callers and blast radius
6. Self-host with `docker compose up` and 5 env vars

Everything else â€” multi-repo, team management, cross-service mesh â€” is v2+.

---

## What NOT to Do

- Do not re-index the whole repo on every PR â€” only touch changed files
- Do not store raw source code â€” symbols, edges, embeddings only
- Do not use a graph database (Neo4j) â€” in-memory + SQL is sufficient
- Do not build the dashboard before the API works â€” test with curl first
- Do not hard-code LLM provider â€” configurable from day one via `LLM_PROVIDER`
- Do not make Postgres required for self-hosting â€” SQLite is the default
- Do not surface `graph_depth` in UI â€” use Fast / Standard / Deep
- Do not break Layer 0 (the existing reviewer) â€” everything wraps around it
